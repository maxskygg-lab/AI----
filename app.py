import streamlit as st
import sys
import os
import time
import tempfile
import arxiv

# ================= ğŸ¥ ç¯å¢ƒå¬è¯Šå™¨ =================
try:
    import zhipuai
    import langchain_community
    import fitz  # pymupdf
except ImportError as e:
    st.error(f"ğŸš‘ ç¯å¢ƒç¼ºå¤±åº“ -> {e.name}")
    st.stop()
# ===============================================

from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import ZhipuAIEmbeddings
from langchain_community.chat_models import ChatZhipuAI
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ================= 2. é¡µé¢é…ç½® =================
st.set_page_config(page_title="AI æ·±åº¦ç ”è¯»åŠ©æ‰‹ (é«˜ç²¾ç‰ˆ)", layout="wide", page_icon="ğŸ“")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px;}
    .reportview-container { margin-top: -2em; }
</style>
""", unsafe_allow_html=True)
st.title("ğŸ“– AI æ·±åº¦ç ”è¯»åŠ©æ‰‹ (é«˜ç²¾åº¦å†…æ ¸ç‰ˆ)")

# ================= 3. çŠ¶æ€åˆå§‹åŒ– =================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "db" not in st.session_state:
    st.session_state.db = None
if "loaded_files" not in st.session_state:
    st.session_state.loaded_files = []
if "suggested_query" not in st.session_state:
    st.session_state.suggested_query = ""
if "search_results" not in st.session_state:
    st.session_state.search_results = []

# ================= 4. æ ¸å¿ƒé€»è¾‘å‡½æ•° =================

def fix_latex_errors(text):
    if not text: return text
    text = text.replace(r"\(", "$").replace(r"\)", "$")
    text = text.replace(r"\[", "$$").replace(r"\]", "$$")
    return text

def process_and_add_to_db(file_path, file_name, api_key):
    try:
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        for doc in docs:
            doc.metadata['source_paper'] = file_name
        
        # âš¡ï¸ æ ¸å¿ƒå‡çº§ 1ï¼šé’ˆå¯¹å­¦æœ¯è®ºæ–‡çš„æ›´ç»†è‡´åˆ‡åˆ†ç­–ç•¥
        # å‡å° chunk_size ä»¥èšç„¦å…·ä½“å®šä¹‰ï¼Œå¢åŠ  overlap ä¿è¯ä¸Šä¸‹æ–‡è¿ç»­
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=600,       # ç¼©å°å—å¤§å°ï¼Œæé«˜æ£€ç´¢å®šä½ç²¾åº¦
            chunk_overlap=200,    # å¢åŠ é‡å ï¼Œé˜²æ­¢å…³é”®å¥å­è¢«åˆ‡æ–­
            separators=["\n\n", "\n", "ã€‚", ".", " ", ""] # ä¼˜å…ˆæŒ‰æ®µè½åˆ‡åˆ†
        )
        chunks = splitter.split_documents(docs)
        valid_chunks = [c for c in chunks if len(c.page_content.strip()) > 20]
        
        embeddings = ZhipuAIEmbeddings(model="embedding-2", api_key=api_key)
        
        batch_size = 10
        total = len(valid_chunks)
        if st.session_state.db is None:
            st.session_state.db = FAISS.from_documents(valid_chunks[:batch_size], embeddings)
            if total > batch_size:
                for i in range(batch_size, total, batch_size):
                    st.session_state.db.add_documents(valid_chunks[i: i + batch_size])
                    time.sleep(0.1)
        else:
            for i in range(0, total, batch_size):
                st.session_state.db.add_documents(valid_chunks[i: i + batch_size])
                time.sleep(0.1)
        
        if file_name not in st.session_state.loaded_files:
            st.session_state.loaded_files.append(file_name)
        
        st.session_state.chat_history.append({
            "role": "system_notice",
            "content": f"ğŸ“š **ç³»ç»Ÿé€šçŸ¥**ï¼šå·²åŠ è½½ã€Š{file_name}ã€‹ã€‚"
        })
    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {e}")

def generate_html_report(chat_history):
    html = """
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>AI ç ”ç©¶ç¬”è®°</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <style>
            body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; line-height: 1.6; color: #333; }
            h1 { border-bottom: 2px solid #4CAF50; padding-bottom: 10px; }
            .message { margin-bottom: 20px; padding: 15px; border-radius: 8px; }
            .user { background-color: #e3f2fd; border-left: 5px solid #2196F3; }
            .assistant { background-color: #f1f8e9; border-left: 5px solid #4CAF50; }
            .system { background-color: #fff3e0; border-left: 5px solid #ff9800; font-style: italic; }
        </style>
    </head>
    <body>
        <h1>ğŸ“ AI æ·±åº¦ç ”è¯»ç¬”è®°</h1>
        <p>å¯¼å‡ºæ—¶é—´ï¼š""" + time.strftime('%Y-%m-%d %H:%M') + """</p>
    """
    for msg in chat_history:
        role_class = msg['role'] if msg['role'] in ['user', 'assistant'] else 'system'
        role_name = "ğŸ§‘â€ğŸ’» æˆ‘" if msg['role'] == 'user' else "ğŸ¤– AI ç ”ç©¶å‘˜" if msg['role'] == 'assistant' else "ğŸ”” ç³»ç»Ÿ"
        content_html = msg['content'].replace('\n', '<br>')
        html += f"""
        <div class="message {role_class}">
            <span class="role-label">{role_name}</span>
            <div>{content_html}</div>
        </div>
        """
    html += "</body></html>"
    return html

# ================= 5. ä¾§è¾¹æ  =================
with st.sidebar:
    st.header("ğŸ›ï¸ æ§åˆ¶å°")
    user_api_key = st.text_input("æ™ºè°± API Key", type="password")

    st.markdown("---")
    st.subheader("âš™ï¸ ç ”è¯»æ¨¡å¼")
    reading_mode = st.radio("é€‰æ‹©æ¨¡å¼:", ["ğŸŸ¢ å¿«é€Ÿé—®ç­”", "ğŸ“– é€æ®µç²¾è¯» (å…¬å¼ä¿®å¤ç‰ˆ)"], index=1)

    st.markdown("---")

    if st.session_state.loaded_files:
        st.success(f"å·²åŠ è½½ {len(st.session_state.loaded_files)} ç¯‡è®ºæ–‡")
        
        # 1. ç»¼è¿°ç”Ÿæˆ
        if st.button("ğŸª„ ä¸€é”®ç”Ÿæˆç»¼è¿°å¯¹æ¯”è¡¨"):
            if not user_api_key:
                st.error("éœ€è¦ API Key")
            elif not st.session_state.db:
                st.warning("æ•°æ®åº“ä¸ºç©º")
            else:
                with st.spinner(f"æ­£åœ¨åˆ†æ..."):
                    try:
                        llm = ChatZhipuAI(model="glm-4", api_key=user_api_key, temperature=0.1)
                        aggregated_context = ""
                        for filename in st.session_state.loaded_files:
                            # å¢å¤§ä¸Šä¸‹æ–‡è·å–é‡ï¼Œä¿è¯æ€»ç»“æ›´å‡†
                            sub_docs = st.session_state.db.similarity_search("Abstract conclusion main contribution", k=3, filter={"source_paper": filename})
                            if sub_docs:
                                file_content = "\n".join([d.page_content for d in sub_docs])
                                aggregated_context += f"\n=== {filename} ===\n{file_content}\n"
                        
                        prompt = f"é˜…è¯»ä»¥ä¸‹è®ºæ–‡æ‘˜è¦ï¼Œç”Ÿæˆ Markdown å¯¹æ¯”è¡¨æ ¼(åˆ—ï¼šè®ºæ–‡å|åˆ›æ–°ç‚¹|æ–¹æ³•|ç»“è®º)ï¼š\n{aggregated_context}"
                        res = llm.invoke(prompt)
                        st.session_state.chat_history.append({"role": "assistant", "content": res.content})
                        st.rerun()
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {e}")

        # 2. æŒ–æ˜å…³è”è®ºæ–‡
        scope_options = ["ğŸŒ å¯¹æ¯”æ‰€æœ‰è®ºæ–‡"] + st.session_state.loaded_files
        selected_scope = st.selectbox("ğŸ‘ï¸ ä¸“æ³¨èŒƒå›´", scope_options)
        
        if st.button(f"ğŸ” åŸºäºã€{selected_scope[:5]}...ã€‘æŒ–æ˜æ–°è®ºæ–‡"):
            if not user_api_key:
                st.error("è¯·å¡«å…¥ API Key")
            else:
                with st.spinner("ğŸ¤– AI æ­£åœ¨æ·±åº¦åˆ†ææ–‡æœ¬ï¼Œæç‚¼æœç´¢è¯..."):
                    try:
                        if selected_scope == "ğŸŒ å¯¹æ¯”æ‰€æœ‰è®ºæ–‡":
                            docs = st.session_state.db.similarity_search("Abstract Future Work limitation", k=5)
                        else:
                            docs = st.session_state.db.similarity_search("Abstract Introduction related work", k=4, filter={"source_paper": selected_scope})
                        
                        content_snippet = "\n".join([d.page_content for d in docs])
                        
                        llm = ChatZhipuAI(model="glm-4", api_key=user_api_key, temperature=0.5)
                        # âš¡ï¸ æ ¸å¿ƒå‡çº§ 2ï¼šæ›´ä¸“ä¸šçš„æœç´¢è¯ Prompt
                        prompt = f"""
                        ä»»åŠ¡ï¼šä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘ç ”åŠ©ç†ã€‚æ ¹æ®ä»¥ä¸‹è®ºæ–‡ç‰‡æ®µï¼Œè¯†åˆ«æ ¸å¿ƒç ”ç©¶é—®é¢˜ã€‚
                        ç›®æ ‡ï¼šç”Ÿæˆ 1 ä¸ªèƒ½åœ¨ ArXiv è·å¾—é«˜è´¨é‡ç»“æœçš„è‹±æ–‡æœç´¢ Queryã€‚
                        è¦æ±‚ï¼š
                        1. å°½é‡ä½¿ç”¨ç»„åˆå…³é”®è¯ï¼ˆå¦‚ "Large Language Model" AND "Reasoning"ï¼‰ã€‚
                        2. æ’é™¤è¿‡äºå®½æ³›çš„è¯ï¼ˆå¦‚ "AI"ï¼‰ã€‚
                        3. åªè¾“å‡º Query å­—ç¬¦ä¸²æœ¬èº«ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
                        
                        ç‰‡æ®µï¼š
                        {content_snippet[:2000]}
                        """
                        generated_query = llm.invoke(prompt).content.strip().replace('"', '').replace("'", "")
                        
                        st.session_state.suggested_query = generated_query
                        
                        search = arxiv.Search(query=generated_query, max_results=5, sort_by=arxiv.SortCriterion.Relevance)
                        st.session_state.search_results = list(search.results())
                        
                        st.success(f"é«˜ç²¾æœç´¢è¯ï¼š{generated_query}")
                        st.info("ğŸ‘ˆ è¯·ç‚¹å‡»ä¸»ç•Œé¢çš„ 'ğŸ” ArXiv æœç´¢' æ ‡ç­¾é¡µæŸ¥çœ‹ç»“æœ")
                    except Exception as e:
                        st.error(f"æŒ–æ˜å¤±è´¥: {e}")

        if st.button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“"):
            st.session_state.db = None
            st.session_state.loaded_files = []
            st.session_state.chat_history = []
            st.rerun()

        st.markdown("---")
        st.subheader("ğŸ“ ç¬”è®°å¯¼å‡º")
        if st.session_state.chat_history:
            html_content = generate_html_report(st.session_state.chat_history)
            st.download_button("ğŸ“„ ä¸‹è½½ç¬”è®° HTML", html_content, "research_notes.html", "text/html")

    st.markdown("---")
    st.subheader("ğŸ“¥ ä¸Šä¼ è®ºæ–‡")
    uploaded_file = st.file_uploader("æ‹–å…¥ PDF", type="pdf")
    if uploaded_file and user_api_key and st.button("ç¡®è®¤åŠ è½½"):
        with st.spinner("è§£æä¸­..."):
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(uploaded_file.getvalue())
                path = tmp.name
            process_and_add_to_db(path, uploaded_file.name, user_api_key)
            os.remove(path)
            st.rerun()

# ================= 6. ä¸»ç•Œé¢ =================
tab_search, tab_chat = st.tabs(["ğŸ” ArXiv æœç´¢", "ğŸ’¬ ç ”è¯»ç©ºé—´"])

with tab_search:
    st.subheader("ğŸŒ ArXiv æ™ºèƒ½æœç´¢")
    col1, col2 = st.columns([4, 1])
    with col1:
        default_query = st.session_state.get("suggested_query", "")
        search_query = st.text_input("è¾“å…¥å…³é”®è¯", value=default_query, placeholder="æ”¯æŒå¸ƒå°”æœç´¢: LLM AND Agent")
    with col2:
        max_results = st.number_input("æ•°é‡", min_value=5, max_value=50, value=10, step=5)
        
    if st.button("ğŸš€ æœç´¢") and search_query:
        with st.spinner(f"æ­£åœ¨æ£€ç´¢ ArXiv (Top {max_results})..."):
            try:
                search = arxiv.Search(query=search_query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)
                st.session_state.search_results = list(search.results())
                st.success(f"æ‰¾åˆ° {len(st.session_state.search_results)} ç¯‡ç›¸å…³è®ºæ–‡")
            except Exception as e:
                st.error(f"æœç´¢å‡ºé”™: {e}")
                
    if "search_results" in st.session_state:
        for res in st.session_state.search_results:
            with st.expander(f"ğŸ“„ {res.title} ({res.published.year})"):
                st.write(f"**ä½œè€…**: {', '.join([a.name for a in res.authors[:3]])}...")
                st.write(f"**æ‘˜è¦**: {res.summary[:300]}...")
                st.markdown(f"[åŸæ–‡é“¾æ¥]({res.entry_id})")
                if st.button(f"â¬‡ï¸ ä¸‹è½½å¹¶ç ”è¯»", key=res.entry_id):
                    if not user_api_key:
                        st.error("è¯·å…ˆé…ç½® API Key")
                    else:
                        with st.spinner("ä¸‹è½½ä¸­..."):
                            try:
                                pdf_path = res.download_pdf(dirpath=tempfile.gettempdir())
                                process_and_add_to_db(pdf_path, res.title, user_api_key)
                                st.success("å…¥åº“æˆåŠŸï¼è½¬åˆ°â€œç ”è¯»ç©ºé—´â€å³å¯å¯¹è¯")
                            except Exception as e:
                                st.error(f"ä¸‹è½½å¤±è´¥: {e}")

with tab_chat:
    if st.session_state.loaded_files:
        st.caption(f"ğŸ“š æ¨¡å¼ï¼š{reading_mode} | èŒƒå›´ï¼š{selected_scope}")

    for msg in st.session_state.chat_history:
        if msg["role"] == "system_notice":
            st.info(msg["content"])
        else:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    if prompt := st.chat_input("è¾“å…¥é—®é¢˜..."):
        if not st.session_state.db:
            st.warning("ğŸ§  è¯·å…ˆæ·»åŠ è®ºæ–‡")
        else:
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)

            with st.chat_message("assistant"):
                try:
                    search_k = 15 if "ç²¾è¯»" in reading_mode else 8
                    try:
                        if selected_scope != "ğŸŒ å¯¹æ¯”æ‰€æœ‰è®ºæ–‡":
                            filter_dict = {"source_paper": selected_scope} 
                        else:
                            filter_dict = None
                    except:
                        filter_dict = None

                    # âš¡ï¸ æ ¸å¿ƒå‡çº§ 3ï¼šä½¿ç”¨ MMR (Maximal Marginal Relevance) ç®—æ³•
                    # ä½œç”¨ï¼šä¸ä»…è¦åƒï¼ˆRelevanceï¼‰ï¼Œè¿˜è¦å¤šæ ·ï¼ˆMarginalï¼‰ã€‚
                    # fetch_k=20: å…ˆæ‰¾ 20 ä¸ªæœ€åƒçš„
                    # lambda_mult=0.6: 0.6çš„æƒé‡ç»™ç›¸å…³æ€§ï¼Œ0.4ç»™å¤šæ ·æ€§ã€‚é˜²æ­¢ AI æ€»æ˜¯å¼•ç”¨åŒä¸€æ®µè¯ã€‚
                    docs = st.session_state.db.max_marginal_relevance_search(
                        prompt, 
                        k=search_k, 
                        fetch_k=20,
                        lambda_mult=0.6,
                        filter=filter_dict
                    )

                    if not docs:
                        st.warning("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")
                        st.stop()

                    context_parts = []
                    for d in docs:
                        source = d.metadata.get('source_paper', 'æœªçŸ¥')
                        page = d.metadata.get('page', 0) + 1
                        context_parts.append(f"ğŸ“„ã€{source} P{page}ã€‘:\n{d.page_content}")

                    full_context = "\n\n".join(context_parts)
                    
                    if "ç²¾è¯»" in reading_mode:
                        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„ç§‘ç ”åŠ©æ‰‹ã€‚åŸºäºèµ„æ–™å›ç­”é—®é¢˜ã€‚
èµ„æ–™ï¼š{full_context}
é—®é¢˜ï¼š{prompt}
è¦æ±‚ï¼š
1. å¿…é¡»ä½¿ç”¨ $...$ åŒ…è£¹æ•°å­¦å…¬å¼ã€‚
2. å°½å¯èƒ½å¼•ç”¨å¤šä¸ªä¸åŒç‰‡æ®µçš„ä¿¡æ¯æ¥å›ç­”ï¼Œä¸è¦åªç›¯ç€ä¸€æ®µã€‚
3. å¿½ç•¥å‚è€ƒæ–‡çŒ®åˆ—è¡¨ã€‚
"""
                    else:
                        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·ç®€è¦å›ç­”ã€‚
èµ„æ–™ï¼š{full_context}
é—®é¢˜ï¼š{prompt}
è¦æ±‚ï¼šå…¬å¼å¿…é¡»ç”¨ $...$ åŒ…è£¹ã€‚
"""
                    llm = ChatZhipuAI(model="glm-4", api_key=user_api_key, temperature=0.1)
                    response = llm.invoke(system_prompt)
                    final_content = fix_latex_errors(response.content)

                    st.write(final_content)
                    st.session_state.chat_history.append({"role": "assistant", "content": final_content})

                except Exception as e:
                    st.error(f"ç”Ÿæˆå‡ºé”™: {e}")
