import streamlit as st
import sys
import os
import time
import tempfile
import arxiv
import requests
import re
from collections import Counter

# ================= 1. ç¯å¢ƒè‡ªæ£€ =================
try:
    import zhipuai
    import langchain_community
    import fitz  # pymupdf
except ImportError as e:
    st.error(f"ğŸš‘ æ ¸å¿ƒç¯å¢ƒç¼ºå¤± -> {e.name}ã€‚è¯·æ‰§è¡Œ: pip install zhipuai langchain_community pymupdf requests arxiv")
    st.stop()

from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import ZhipuAIEmbeddings
from langchain_community.chat_models import ChatZhipuAI
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ================= 2. é¡µé¢é…ç½®ä¸ CSS æ ·å¼è¡¨ (å®Œæ•´è¿˜åŸ) =================
st.set_page_config(page_title="AI æ·±åº¦ç ”è¯»åŠ©æ‰‹ (å…¨åŠŸèƒ½ç»ˆæç‰ˆ)", layout="wide", page_icon="ğŸ“")
st.markdown("""
<style>
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; }
    .abstract-box {
        background-color: #f1f3f5; padding: 20px; border-radius: 12px;
        border-left: 6px solid #28a745; font-size: 0.98em; line-height: 1.8;
        margin-bottom: 15px; color: #343a40; box-shadow: 2px 2px 5px rgba(0,0,0,0.05);
    }
    .cite-badge {
        background-color: #dc3545; color: white; padding: 4px 14px;
        border-radius: 20px; font-size: 0.85em; font-weight: bold;
    }
    .topic-tag {
        display: inline-block; background-color: #e7f3ff; color: #007bff;
        padding: 5px 12px; border-radius: 6px; margin: 5px;
        font-size: 0.88em; border: 1px solid #cce5ff; font-weight: 500;
    }
    .metric-card {
        background-color: white; padding: 15px; border-radius: 10px;
        border: 1px solid #dee2e6; text-align: center; box-shadow: 1px 1px 3px rgba(0,0,0,0.05);
    }
</style>
""", unsafe_allow_html=True)
st.title("ğŸ“– AI æ·±åº¦ç ”è¯»åŠ©æ‰‹ (å…¨åŠŸèƒ½æ¢å¤ç‰ˆ)")

# ================= 3. å…¨å±€çŠ¶æ€åˆå§‹åŒ– =================
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "db" not in st.session_state: st.session_state.db = None
if "loaded_files" not in st.session_state: st.session_state.loaded_files = []
if "all_chunks" not in st.session_state: st.session_state.all_chunks = []
if "suggested_query" not in st.session_state: st.session_state.suggested_query = ""
if "search_results" not in st.session_state: st.session_state.search_results = []
if "selected_scope" not in st.session_state: st.session_state.selected_scope = "ğŸŒ å¯¹æ¯”æ‰€æœ‰è®ºæ–‡"

# ================= 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•°é›† =================

def fetch_citations(arxiv_id):
    """ä» Semantic Scholar å®æ—¶è°ƒå–å¼•ç”¨é‡æ•°æ®"""
    try:
        clean_id = arxiv_id.split('/')[-1].split('v')[0]
        api_url = f"https://api.semanticscholar.org/graph/v1/paper/ArXiv:{clean_id}?fields=citationCount"
        response = requests.get(api_url, timeout=5)
        if response.status_code == 200:
            return response.json().get('citationCount', 0)
    except Exception:
        pass
    return 0

def extract_top_topics(results):
    """å­¦æœ¯çƒ­ç‚¹è¯åˆ†æ (Google æ£€ç´¢é€»è¾‘)"""
    all_text = ""
    for item in results:
        res = item['obj']
        all_text += f" {res.title} {res.summary}"
    words = re.findall(r'\b\w{5,}\b', all_text.lower())
    stop_words = {'learning', 'robotics', 'education', 'research', 'paper', 'approach', 'system', 'based', 'using', 'results', 'provide', 'model', 'analysis', 'method'}
    meaningful_words = [w for w in words if w not in stop_words]
    return Counter(meaningful_words).most_common(10)

def fix_latex_errors(text):
    """æ·±åº¦ä¿®å¤ LaTeX æ¸²æŸ“æ ‡è¯†é—®é¢˜"""
    if not text: return text
    text = text.replace(r"\(", "$").replace(r"\)", "$")
    text = text.replace(r"\[", "$$").replace(r"\]", "$$")
    return text

def generate_html_report(chat_history):
    """å¯¼å‡ºå¸¦ MathJax æ¸²æŸ“æ”¯æŒçš„ä¸“ä¸š HTML æŠ¥å‘Š"""
    html = """<!DOCTYPE html><html><head><meta charset="UTF-8">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 900px; margin: 0 auto; padding: 40px; line-height: 1.7; color: #333; background-color: #f9f9f9; }
        h1 { color: #1b5e20; border-bottom: 3px solid #4caf50; padding-bottom: 12px; }
        .message { margin-bottom: 30px; padding: 25px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
        .user { background-color: #e3f2fd; border-left: 8px solid #1976d2; }
        .assistant { background-color: #f1f8e9; border-left: 8px solid #43a047; }
        .system { background-color: #fff3e0; border-left: 8px solid #fb8c00; font-style: italic; color: #666; }
        .role-title { font-weight: bold; display: block; margin-bottom: 12px; text-transform: uppercase; font-size: 0.85em; color: #555; }
        pre { background: #eee; padding: 10px; border-radius: 5px; overflow-x: auto; }
    </style></head><body><h1>ğŸ“ AI æ·±åº¦ç ”è¯»ç¬”è®°æŠ¥å‘Š</h1>"""
    for msg in chat_history:
        role_label = "ğŸ§‘â€ğŸ’» æˆ‘" if msg['role'] == 'user' else "ğŸ¤– AI ç ”ç©¶å‘˜" if msg['role'] == 'assistant' else "ğŸ”” ç³»ç»Ÿç³»ç»Ÿé€šçŸ¥"
        content_formatted = msg['content'].replace('\n', '<br>')
        html += f'<div class="message {msg["role"]}"><span class="role-title">{role_label}</span>{content_formatted}</div>'
    html += "</body></html>"
    return html

def rebuild_index_from_chunks(api_key):
    """ç‰©ç†åˆ é™¤æ–‡æ¡£åé‡æ„å‘é‡ç´¢å¼• (å« Batch ä¿æŠ¤)"""
    if not st.session_state.all_chunks:
        st.session_state.db = None
        return
    embeddings = ZhipuAIEmbeddings(model="embedding-2", api_key=api_key)
    chunks = st.session_state.all_chunks
    batch_size = 32
    st.session_state.db = FAISS.from_documents(chunks[:batch_size], embeddings)
    for i in range(batch_size, len(chunks), batch_size):
        st.session_state.db.add_documents(chunks[i:i+batch_size])
        time.sleep(0.1)

def process_and_add_to_db(file_path, file_name, api_key):
    """è§£æ PDF å¹¶æ‰§è¡Œåˆ†æ‰¹æ¬¡å‘é‡åŒ– (å½»åº•ä¿®å¤ 1214 é”™è¯¯)"""
    try:
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        for doc in docs:
            doc.metadata['source_paper'] = file_name
        
        splitter = RecursiveCharacterTextSplitter(chunk_size=750, chunk_overlap=200, separators=["\n\n", "\n", "ã€‚", ".", " ", ""])
        new_chunks = splitter.split_documents(docs)
        valid_new = [c for c in new_chunks if len(c.page_content.strip()) > 30]
        
        embeddings = ZhipuAIEmbeddings(model="embedding-2", api_key=api_key)
        
        # --- åˆ†æ‰¹å¤„ç†æ ¸å¿ƒé€»è¾‘ ---
        batch_size = 32
        total_len = len(valid_new)
        with st.spinner(f"æ­£åœ¨å‘é‡åŒ–ã€Š{file_name}ã€‹ï¼Œå…± {total_len} ä¸ªç‰‡æ®µï¼Œåˆ†æ‰¹ä¸Šä¼ ä¸­..."):
            if st.session_state.db is None:
                st.session_state.db = FAISS.from_documents(valid_new[:batch_size], embeddings)
                current_start = batch_size
            else:
                current_start = 0
            
            for i in range(current_start, total_len, batch_size):
                batch_data = valid_new[i : i + batch_size]
                st.session_state.db.add_documents(batch_data)
                time.sleep(0.2) # é˜²æ­¢ API é¢‘ç‡é™åˆ¶
        
        st.session_state.all_chunks.extend(valid_new)
        if file_name not in st.session_state.loaded_files:
            st.session_state.loaded_files.append(file_name)
        st.session_state.chat_history.append({"role": "system_notice", "content": f"ğŸ“š **åº“æ›´æ–°**ï¼šæˆåŠŸåŠ è½½å¹¶ç´¢å¼•æ–‡æ¡£ã€Š{file_name}ã€‹"})
    except Exception as e:
        st.error(f"è§£æå¤±è´¥: {str(e)}")

# ================= 5. ä¾§è¾¹æ ï¼šæ§åˆ¶é¢æ¿ (å®Œæ•´è¿˜åŸåŠŸèƒ½) =================
with st.sidebar:
    st.header("ğŸ›ï¸ ç§‘ç ”å·¥ä½œå°")
    user_api_key = st.text_input("æ™ºè°± API Key", type="password", help="è¯·å¡«å†™ GLM-4 æœ‰æ•ˆ Key")
    st.markdown("---")
    
    if st.session_state.loaded_files:
        st.subheader("ğŸ—‚ï¸ æ–‡çŒ®åº“ç®¡ç†")
        for file in list(st.session_state.loaded_files):
            col_f, col_d = st.columns([4, 1])
            with col_f: st.caption(f"ğŸ“„ {file[:25]}...")
            with col_d:
                if st.button("ğŸ—‘ï¸", key=f"del_{file}"):
                    st.session_state.loaded_files.remove(file)
                    st.session_state.all_chunks = [c for c in st.session_state.all_chunks if c.metadata.get('source_paper') != file]
                    if user_api_key: rebuild_index_from_chunks(user_api_key)
                    st.rerun()

        st.markdown("---")
        # æ ¸å¿ƒåŠŸèƒ½ 1: ç»¼è¿°å¯¹æ¯”è¡¨
        if st.button("ğŸª„ ä¸€é”®ç”Ÿæˆç»¼è¿°å¯¹æ¯”è¡¨", type="primary"):
            if user_api_key and st.session_state.db:
                with st.spinner("æ¨ªå‘æ‰«ææ–‡çŒ®ä¸­..."):
                    llm = ChatZhipuAI(model="glm-4", api_key=user_api_key, temperature=0.1)
                    comparison_ctx = ""
                    for paper in st.session_state.loaded_files:
                        top_sub = st.session_state.db.similarity_search("Abstract methodology contribution", k=3, filter={"source_paper": paper})
                        comparison_ctx += f"\n[æ–‡ç« : {paper}]\n" + "\n".join([d.page_content for d in top_sub])
                    prompt = f"å¯¹æ¯”ä»¥ä¸‹ç§‘ç ”æ–‡çŒ®ï¼Œç”Ÿæˆä¸€ä¸ª Markdown è¡¨æ ¼ï¼ŒåŒ…å«ï¼šè®ºæ–‡åã€æ ¸å¿ƒåˆ›æ–°ç‚¹ã€ä¸»è¦æ–¹æ³•ã€ç ”ç©¶å±€é™ã€‚å†…å®¹å¦‚ä¸‹ï¼š\n{comparison_ctx}"
                    response = llm.invoke(prompt)
                    st.session_state.chat_history.append({"role": "assistant", "content": response.content})
                    st.rerun()

        st.markdown("---")
        st.session_state.selected_scope = st.selectbox("ğŸ‘ï¸ å¯¹è¯ä¸“æ³¨èŒƒå›´", ["ğŸŒ å¯¹æ¯”æ‰€æœ‰è®ºæ–‡"] + st.session_state.loaded_files)

        # æ ¸å¿ƒåŠŸèƒ½ 2: æŒ–æ˜å…³è”è®ºæ–‡
        if st.button(f"ğŸ” æŒ–æ˜ã€{st.session_state.selected_scope[:6]}ã€‘å…³è”è¯"):
            if user_api_key and st.session_state.db:
                with st.spinner("AI æ·±åº¦ç‰¹å¾æç‚¼ä¸­..."):
                    scope = st.session_state.selected_scope
                    f_dict = {"source_paper": scope} if scope != "ğŸŒ å¯¹æ¯”æ‰€æœ‰è®ºæ–‡" else None
                    key_docs = st.session_state.db.similarity_search("Introduction future work research gap", k=4, filter=f_dict)
                    llm = ChatZhipuAI(model="glm-4", api_key=user_api_key)
                    prompt = f"åŸºäºä»¥ä¸‹æ–‡æœ¬ç‰‡æ®µï¼Œæç‚¼ 2 ä¸ªæœ€ç²¾å‡†çš„è‹±æ–‡å­¦æœ¯æœç´¢è¯ç»„ï¼Œç”¨äºè¿›ä¸€æ­¥æ£€ç´¢ç›¸å…³æ–‡çŒ®ï¼ˆåªè¾“å‡ºè¯ç»„ï¼‰ï¼š\n" + "\n".join([d.page_content for d in key_docs])
                    new_q = llm.invoke(prompt).content.strip()
                    st.session_state.suggested_query = new_q
                    st.success(f"æ–°æœç´¢è¯å·²ç”Ÿæˆï¼")
                    st.rerun()

    st.markdown("---")
    if st.session_state.chat_history:
        st.download_button("ğŸ’¾ ä¸‹è½½ç ”è¯»æŠ¥å‘Š (HTML)", generate_html_report(st.session_state.chat_history), "study_report.html", "text/html")
    
    st.subheader("ğŸ“¥ å¯¼å…¥æœ¬åœ°æ–‡çŒ®")
    uploaded_pdf = st.file_uploader("ä¸Šä¼  PDF è®ºæ–‡", type="pdf")
    if uploaded_pdf and user_api_key and st.button("å¼€å§‹è§£æ"):
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_pdf.getvalue())
            process_and_add_to_db(tmp.name, uploaded_pdf.name, user_api_key)
            os.remove(tmp.name)
            st.rerun()

# ================= 6. ä¸»ç•Œé¢ =================
tab_search, tab_chat = st.tabs(["ğŸ” æ–‡çŒ®è°ƒç ”å¼•æ“ (Google Logic)", "ğŸ’¬ æ·±åº¦ç ”è¯»å¯¹è¯"])

with tab_search:
    st.subheader("ğŸŒ å­¦æœ¯å¤§æ•°æ®è”åˆè°ƒç ”")
    col_q, col_s, col_n = st.columns([3, 1.2, 0.8])
    with col_q:
        input_q = st.text_input("å…³é”®è¯/æŒ–æ˜è¯", value=st.session_state.suggested_query, placeholder="ä¾‹å¦‚: robotics education human-robot interaction")
    with col_s:
        sort_mode = st.selectbox("æ’åºé€»è¾‘", ["ğŸ”¥ ç›¸å…³æ€§ä¼˜å…ˆ", "ğŸ“… æ—¶é—´æœ€æ–°", "ğŸ“ˆ å¼•ç”¨é‡ä¹‹ç‹"])
    with col_n:
        n_results = st.number_input("ç¯‡æ•°", 5, 50, 15)

    if st.button("ğŸš€ å¯åŠ¨æ·±åº¦æ£€ç´¢") and input_q:
        with st.spinner("æ­£åœ¨æ£€ç´¢å¹¶åŒæ­¥ Citation æ•°æ®..."):
            try:
                arxiv_sort = arxiv.SortCriterion.Relevance
                if "æ—¶é—´" in sort_mode: arxiv_sort = arxiv.SortCriterion.SubmittedDate
                
                # å¸ƒå°”æ£€ç´¢ä¼˜åŒ–
                processed_q = input_q if ("AND" in input_q) else " AND ".join([f"(ti:{w} OR abs:{w})" for w in input_q.split()])
                search_client = arxiv.Search(query=processed_q, max_results=n_results, sort_by=arxiv_sort)
                results_with_meta = []
                for res in list(search_client.results()):
                    results_with_meta.append({'obj': res, 'citations': fetch_citations(res.entry_id)})
                    time.sleep(0.1)
                
                if "å¼•ç”¨é‡" in sort_mode:
                    results_with_meta.sort(key=lambda x: x['citations'], reverse=True)
                st.session_state.search_results = results_with_meta
            except Exception as e:
                st.error(f"æ£€ç´¢å‡ºé”™: {e}")

    if st.session_state.search_results:
        # è¡¥å…¨åŠŸèƒ½ 3: é¢†åŸŸå…³é”®è¯çƒ­åº¦åˆ†å¸ƒ
        topics = extract_top_topics(st.session_state.search_results)
        st.write("ğŸ“Š **å½“å‰è°ƒç ”çƒ­ç‚¹ç»Ÿè®¡** (æœ‰åŠ©äºè¯†åˆ«ç ”ç©¶åå‘):")
        topic_cols = st.columns(len(topics))
        for i, (word, count) in enumerate(topics):
            topic_cols[i].markdown(f"<div class='topic-tag'>{word} ({count})</div>", unsafe_allow_html=True)
        
        st.markdown("---")
        for i, item in enumerate(st.session_state.search_results):
            res, cites = item['obj'], item['citations']
            is_precise = any(w.lower() in res.title.lower() for w in input_q.split()[:1])
            with st.expander(f"{'ğŸ¯' if is_precise else 'ğŸ“„'} #{i+1} [{cites} å¼•ç”¨] {res.title} ({res.published.year})"):
                clean_abs = res.summary.replace('\n', ' ')
                st.markdown(f"<div class='abstract-box'><b>Abstract:</b><br>{clean_abs}</div>", unsafe_allow_html=True)
                col1, col2 = st.columns([1, 1])
                with col1: st.markdown(f"[ğŸ”— ArXiv åœ°å€]({res.entry_id})")
                with col2:
                    if st.button(f"â¬‡ï¸ ä¸‹è½½å¹¶ç ”è¯»æ­¤ç¯‡", key=f"dl_btn_{i}"):
                        if user_api_key:
                            with st.spinner("æ­£åœ¨åˆ†æ‰¹ç´¢å¼•..."):
                                pdf_path = res.download_pdf(dirpath=tempfile.gettempdir())
                                process_and_add_to_db(pdf_path, res.title, user_api_key)
                                st.success("å·²å®Œæˆï¼")
                        else: st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ å¡«å†™ API Key")

with tab_chat:
    if st.session_state.loaded_files:
        st.caption(f"ğŸ“š ç ”è¯»èŒƒå›´: {st.session_state.selected_scope}")
        for msg in st.session_state.chat_history:
            if msg["role"] == "system_notice": st.info(msg["content"])
            else:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])

        if prompt := st.chat_input("é’ˆå¯¹é€‰ä¸­è®ºæ–‡è¿›è¡Œæ·±åº¦æé—®..."):
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.write(prompt)
            with st.chat_message("assistant"):
                try:
                    scope = st.session_state.selected_scope
                    f_dict = {"source_paper": scope} if scope != "ğŸŒ å¯¹æ¯”æ‰€æœ‰è®ºæ–‡" else None
                    # MMR æ£€ç´¢é€»è¾‘è¡¥å…¨
                    search_docs = st.session_state.db.max_marginal_relevance_search(
                        prompt, k=7, fetch_k=20, lambda_mult=0.75, filter=f_dict
                    )
                    context_str = "\n\n".join([f"ğŸ“„ã€{d.metadata.get('source_paper','?')} P{d.metadata.get('page',0)+1}ã€‘:\n{d.page_content}" for d in search_docs])
                    
                    llm_chat = ChatZhipuAI(model="glm-4", api_key=user_api_key, temperature=0.1)
                    full_prompt = f"ä½ æ˜¯èµ„æ·±ç§‘ç ”ä¸“å®¶ã€‚åŸºäºä»¥ä¸‹è®ºæ–‡èµ„æ–™å›ç­”ï¼š\n{context_str}\n\né—®é¢˜ï¼š{prompt}\nè¦æ±‚ï¼šä¸¥è°¨å¼•ç”¨ï¼Œæ•°å­¦å…¬å¼åŠ¡å¿…ç”¨ $ åŒ…è£¹ã€‚"
                    ans_res = llm_chat.invoke(full_prompt)
                    final_ans = fix_latex_errors(ans_res.content)
                    st.write(final_ans)
                    st.session_state.chat_history.append({"role": "assistant", "content": final_ans})
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
    else:
        st.info("ğŸ’¡ ç ”è¯»åº“ä¸ºç©ºã€‚è¯·å…ˆé€šè¿‡æ£€ç´¢ä¸‹è½½è®ºæ–‡ï¼Œæˆ–æ‰‹åŠ¨ä¸Šä¼  PDF æ–‡ä»¶ã€‚")
